<div class="recognition-container">
  <div class="header">
    <h2>ğŸ¥ Live Face Recognition</h2>
    <div class="controls">
      <!-- Camera Selector -->
      <div class="camera-selector" *ngIf="availableCameras.length > 0">
        <label for="camera-select">ğŸ“· Camera:</label>
        <select 
          id="camera-select" 
          [(ngModel)]="selectedCameraId" 
          (change)="onCameraChange($event)"
          [disabled]="isLoadingCameras">
          <option *ngFor="let camera of availableCameras" [value]="camera.id">
            {{ camera.name }} ({{ camera.id }})
          </option>
        </select>
        <span class="current-camera" *ngIf="isStreaming">
          ğŸ“¹ Current: Camera {{ currentCameraId }}
        </span>
      </div>
      
      <button class="btn btn-primary" *ngIf="!isConnected" (click)="startRecognition()">
        â–¶ï¸ Start Recognition
      </button>
      <button class="btn btn-danger" *ngIf="isConnected" (click)="stopRecognition()">
        â¹ï¸ Stop Recognition
      </button>
      <button class="btn btn-secondary" *ngIf="isConnected" (click)="restart()">
        ğŸ”„ Restart
      </button>
    </div>
  </div>

  <!-- Status Bar -->
  <div class="status-bar">
    <div class="status-item">
      <span class="label">Status:</span>
      <span class="value" [class.connected]="isConnected" [class.disconnected]="!isConnected">
        {{ isConnected ? (isStreaming ? 'ğŸŸ¢ Streaming' : 'ğŸŸ¡ Connected') : 'ğŸ”´ Disconnected' }}
      </span>
    </div>
    <div class="status-item" *ngIf="isStreaming">
      <span class="label">FPS:</span>
      <span class="value">{{ fps }}</span>
    </div>
    <div class="status-item" *ngIf="currentFaces.length > 0">
      <span class="label">Faces Detected:</span>
      <span class="value">{{ currentFaces.length }}</span>
    </div>
  </div>

  <!-- Messages -->
  <div class="info-message" *ngIf="message && !errorMessage">
    â„¹ï¸ {{ message }}
  </div>

  <div class="error-message" *ngIf="errorMessage">
    âŒ {{ errorMessage }}
  </div>

  <!-- Video Canvas -->
  <div class="video-wrapper">
    <canvas #canvasElement></canvas>
    
    <!-- No Stream Overlay -->
    <div class="no-stream-overlay" *ngIf="!isStreaming">
      <div class="placeholder-icon">ğŸ“¹</div>
      <p *ngIf="!isConnected">Click "Start Recognition" to begin</p>
      <p *ngIf="isConnected && !isStreaming">Waiting for video stream...</p>
    </div>
  </div>

  <!-- Recognized Faces List -->
  <div class="faces-list" *ngIf="currentFaces.length > 0">
    <h3>âœ… Recognized Employees</h3>
    <div class="face-cards">
      <div class="face-card" *ngFor="let face of currentFaces; trackBy: trackByEmployeeCode">
        <div class="face-info">
          <div class="face-icon">ğŸ‘¤</div>
          <div class="face-details">
            <h4>{{ face.employee_name }}</h4>
            <p class="employee-code">{{ face.employee_code }}</p>
            <p class="confidence">
              Confidence: 
              <span [class.high]="face.confidence_score >= 0.8" 
                    [class.medium]="face.confidence_score >= 0.6 && face.confidence_score < 0.8"
                    [class.low]="face.confidence_score < 0.6">
                {{ (face.confidence_score * 100).toFixed(1) }}%
              </span>
            </p>
            <p class="method">Method: {{ face.recognition_method }}</p>
          </div>
        </div>
        <div class="face-status">
          âœ… Verified
        </div>
      </div>
    </div>
  </div>

  <!-- No Faces Detected -->
  <div class="no-faces" *ngIf="isStreaming && currentFaces.length === 0">
    <p>ğŸ‘ï¸ No faces detected in frame</p>
    <p class="sub-text">Please position yourself in front of the camera</p>
  </div>
</div>
